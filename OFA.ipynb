{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgw6JHkZVcdK",
        "outputId": "fa3c1980-beb5-4eb6-9d95-886e7e5d71fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OFA'...\n",
            "remote: Enumerating objects: 6403, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 6403 (delta 6), reused 11 (delta 4), pack-reused 6381\u001b[K\n",
            "Receiving objects: 100% (6403/6403), 122.11 MiB | 40.73 MiB/s, done.\n",
            "Resolving deltas: 100% (2613/2613), done.\n",
            "/content/OFA\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/OFA/fairseq (from -r requirements.txt (line 1))\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (4.6.0.66)\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[K     |████████████████████████████████| 549 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting ftfy==6.0.3\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting tensorboardX==2.4.1\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 72.1 MB/s \n",
            "\u001b[?25hCollecting pycocotools==2.0.4\n",
            "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 64.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycocoevalcap==1.2\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 104.3 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-1.8.3.post1-py3-none-any.whl (798 kB)\n",
            "\u001b[K     |████████████████████████████████| 798 kB 68.5 MB/s \n",
            "\u001b[?25hCollecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 513 kB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 78.3 MB/s \n",
            "\u001b[?25hCollecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Collecting python-Levenshtein\n",
            "  Downloading python_Levenshtein-0.20.8-py3-none-any.whl (9.4 kB)\n",
            "Collecting zhconv\n",
            "  Downloading zhconv-1.4.3.tar.gz (211 kB)\n",
            "\u001b[K     |████████████████████████████████| 211 kB 83.9 MB/s \n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (2022.6.2)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (1.15.1)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 75.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (4.64.1)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 79.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (0.29.32)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 71.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from ftfy==6.0.3->-r requirements.txt (line 4)) (0.2.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX==2.4.1->-r requirements.txt (line 5)) (3.19.6)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from pycocotools==2.0.4->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (5.10.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 70.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.4->-r requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.4->-r requirements.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.4->-r requirements.txt (line 6)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0.4->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools==2.0.4->-r requirements.txt (line 6)) (1.15.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (0.8.10)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (4.9.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 91.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from timm->-r requirements.txt (line 3)) (0.13.1+cu113)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.8/dist-packages (from timm->-r requirements.txt (line 3)) (1.12.1+cu113)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning->-r requirements.txt (line 8)) (2022.11.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning->-r requirements.txt (line 8)) (21.3)\n",
            "Collecting lightning-utilities==0.3.*\n",
            "  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
            "\u001b[K     |████████████████████████████████| 512 kB 52.3 MB/s \n",
            "\u001b[?25hCollecting fire\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (2.23.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (3.8.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (1.3.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (22.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (1.8.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (2.10)\n",
            "Collecting multiprocess\n",
            "  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 85.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets->-r requirements.txt (line 10)) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 78.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets->-r requirements.txt (line 10)) (0.3.6)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets->-r requirements.txt (line 10)) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm->-r requirements.txt (line 3)) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning->-r requirements.txt (line 8)) (2022.9.24)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 95.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from rouge_score->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from rouge_score->-r requirements.txt (line 11)) (3.7)\n",
            "Collecting Levenshtein==0.20.8\n",
            "  Downloading Levenshtein-0.20.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (174 kB)\n",
            "\u001b[K     |████████████████████████████████| 174 kB 81.3 MB/s \n",
            "\u001b[?25hCollecting rapidfuzz<3.0.0,>=2.3.0\n",
            "  Downloading rapidfuzz-2.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 72.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (2.21)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning->-r requirements.txt (line 8)) (2.1.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+5fd17e7->-r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score->-r requirements.txt (line 11)) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->rouge_score->-r requirements.txt (line 11)) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->-r requirements.txt (line 10)) (2022.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->timm->-r requirements.txt (line 3)) (7.1.2)\n",
            "Building wheels for collected packages: ftfy, pycocotools, antlr4-python3-runtime, rouge-score, zhconv, fire\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=bbe3b4ccde3eb52d15e3e94624830a6b139040a3730580235715636392f8acac\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/40/63/4bf603cec3ecc4a26985405834cb47eb8368bfa59e15dde046\n",
            "  Building wheel for pycocotools (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp38-cp38-linux_x86_64.whl size=304282 sha256=b23b71a861f20a7be92dc44d9adf6055f528ca05f2f4e758f4fc19b5029379f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/e2/43/3e93cd653b3346b3d702bb0509bc611189f95d60407bff1484\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=2a78bac20bfa725dcbef718c5a9dcfc429e512859f295cc44c7058fd988617ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=250a8e500719351e5d9faa11fb7fe09d5bdbb43a75f5cedeb5e0da88d638aa7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/55/6f/ebfc4cb176d1c9665da4e306e1705496206d08215c1acd9dde\n",
            "  Building wheel for zhconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for zhconv: filename=zhconv-1.4.3-py2.py3-none-any.whl size=208852 sha256=b2447cffcdd46be93dd20ebf5cfcd9108c1969e7dbd0e718ff7d51eb7af09018\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/11/df/c14a55367e9dc3cf3d605f1335d484797fc01c9d61de740bb3\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=a726a52f4b0e0dc506f68773e802f78d73220432a76c7114020a178566f2ee60\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
            "Successfully built ftfy pycocotools antlr4-python3-runtime rouge-score zhconv fire\n",
            "Installing collected packages: urllib3, rapidfuzz, portalocker, omegaconf, fire, colorama, antlr4-python3-runtime, xxhash, torchmetrics, tensorboardX, sacrebleu, responses, pycocotools, multiprocess, lightning-utilities, Levenshtein, hydra-core, huggingface-hub, bitarray, zhconv, timm, rouge-score, pytorch-lightning, python-Levenshtein, pycocoevalcap, ftfy, fairseq, einops, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.6\n",
            "    Uninstalling pycocotools-2.0.6:\n",
            "      Successfully uninstalled pycocotools-2.0.6\n",
            "  Running setup.py develop for fairseq\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/content/OFA/fairseq/setup.py'\"'\"'; __file__='\"'\"'/content/OFA/fairseq/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' develop --no-deps Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/OFA-Sys/OFA\n",
        "%cd OFA\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/pytorch/fairseq.git -b v0.12.0\n",
        "%cd /content/fairseq\n",
        "!pip install --use-feature=in-tree-build ./"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnva3djjgt-c",
        "outputId": "178b436b-d9bc-46df-8dc1-2f79732b1894"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 33405, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 33405 (delta 0), reused 1 (delta 0), pack-reused 33404\u001b[K\n",
            "Receiving objects: 100% (33405/33405), 23.29 MiB | 34.56 MiB/s, done.\n",
            "Resolving deltas: 100% (24390/24390), done.\n",
            "Note: checking out '6795311bfeb9d39fe11a62803184b81acb66509e'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "/content/fairseq\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (0.12.1+cu113)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (4.64.1)\n",
            "Requirement already satisfied: omegaconf<2.1 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (2.0.6)\n",
            "Requirement already satisfied: hydra-core<1.1,>=1.0.7 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (1.0.7)\n",
            "Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (2.3.1)\n",
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (2.6.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (0.29.32)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq==0.12.0) (1.15.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==0.12.0) (4.8)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==0.12.0) (5.10.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==0.12.0) (4.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq==0.12.0) (6.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.0) (2.6.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.0) (4.9.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.0) (0.4.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq==0.12.0) (0.8.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq==0.12.0) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==0.12.0) (3.10.0)\n",
            "Building wheels for collected packages: fairseq\n",
            "  Building wheel for fairseq (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.0-cp38-cp38-linux_x86_64.whl size=15462504 sha256=d8700b3dd32c072e119086c3bf1c2992997245a60ca0c43f714c7bc979b2ff38\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gix19pju/wheels/45/ac/c1/5c3c02c0e0520a71d95d020995fe3cecb9b9185ac4a3832ef6\n",
            "Successfully built fairseq\n",
            "Installing collected packages: fairseq\n",
            "Successfully installed fairseq-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzX013wUx8Fk",
        "outputId": "abf00be4-6565-4e85-f341-5457932f2670"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/OFA\n",
        "!mkdir checkpoints dataset\n",
        "!mkdir dataset/refcoco_data"
      ],
      "metadata": {
        "id": "M-OtnY4kgNeQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad5217c5-dc44-4472-a617-e753c91c21e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OFA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/refcoco_large_best.pt -d /content/OFA/checkpoints/"
      ],
      "metadata": {
        "id": "HmuG-ccGfZIQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!unzip /content/drive/MyDrive/refcoco_data.zip -d /content/OFA/dataset/refcoco_data\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YCLQE97hDmt",
        "outputId": "4cccf1aa-b40a-48ad-e63e-e6cc59513f9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Using cached einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "Archive:  /content/drive/MyDrive/refcoco_data.zip\n",
            "  inflating: /content/OFA/dataset/refcoco_data/refcoco_testA.tsv  \n",
            "  inflating: /content/OFA/dataset/refcoco_data/refcoco_testB.tsv  \n",
            "  inflating: /content/OFA/dataset/refcoco_data/refcoco_train.tsv  \n",
            "  inflating: /content/OFA/dataset/refcoco_data/refcoco_val.tsv  \n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Using cached datasets-2.7.1-py3-none-any.whl (451 kB)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: datasets\n",
            "Successfully installed datasets-2.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd run_scripts/refcoco ; sh evaluate_refcoco.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wIEF26Pzk-y",
        "outputId": "e929a7bd-08f3-4bb2-8c07-8248c5fdc5e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2022-12-02 07:53:40 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmpa48n5_4g\n",
            "2022-12-02 07:53:40 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmpa48n5_4g/_remote_module_non_scriptable.py\n",
            "2022-12-02 07:53:40 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-12-02 07:53:43 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://\n",
            "2022-12-02 07:53:43 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "2022-12-02 07:53:43 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "2022-12-02 07:53:43 | INFO | fairseq.distributed.utils | initialized host df5edc4d0afe as rank 0\n",
            "2022-12-02 07:53:47 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../../checkpoints/refcoco_large_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{\"data\":\"../../dataset/refcoco_data/refcoco_val.tsv\",\"bpe_dir\":\"../../utils/BPE\",\"selected_cols\":\"0,4,2,3\"}', 'results_path': '../../results/refcoco'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'refcoco_val', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 4, 'min_len': 4, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../dataset/refcoco_data/refcoco_val.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-02 07:53:47 | INFO | ofa.evaluate | loading model(s) from ../../checkpoints/refcoco_large_best.pt\n",
            "tcmalloc: large alloc 1891909632 bytes == 0xe5f0a000 @  0x7f4412f54b6b 0x7f4412f74379 0x7f4396e8dd57 0x7f4396e7bbc3 0x7f43c2a5f230 0x7f43e8d06bc4 0x7f43e89aca3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e858 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69\n",
            "tcmalloc: large alloc 1891909632 bytes == 0x15740c000 @  0x7f4412f54b6b 0x7f4412f74379 0x7f4396e8dd57 0x7f4396e7bbc3 0x7f43c2a5f230 0x7f43e8d06bc4 0x7f43e89aca3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e858 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69\n",
            "2022-12-02 07:54:15 | INFO | tasks.ofa_task | source dictionary: 59457 types\n",
            "2022-12-02 07:54:15 | INFO | tasks.ofa_task | target dictionary: 59457 types\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "local datafile ../../dataset/refcoco_data/refcoco_val.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping\n",
            "local datafile ../../dataset/refcoco_data/refcoco_val.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping\n",
            "file ../../dataset/refcoco_data/refcoco_val.tsv slice_id 0 row count 10834 total row count 10834\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/content/OFA/models/sequence_generator.py:695: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "2022-12-02 07:55:06 | INFO | fairseq.logging.progress_bar | :     11 / 678 sentences=16\n",
            "2022-12-02 07:55:33 | INFO | fairseq.logging.progress_bar | :     21 / 678 sentences=16\n",
            "2022-12-02 07:56:02 | INFO | fairseq.logging.progress_bar | :     31 / 678 sentences=16\n",
            "2022-12-02 07:56:29 | INFO | fairseq.logging.progress_bar | :     41 / 678 sentences=16\n",
            "2022-12-02 07:56:56 | INFO | fairseq.logging.progress_bar | :     51 / 678 sentences=16\n",
            "2022-12-02 07:57:23 | INFO | fairseq.logging.progress_bar | :     61 / 678 sentences=16\n",
            "2022-12-02 07:57:51 | INFO | fairseq.logging.progress_bar | :     71 / 678 sentences=16\n",
            "2022-12-02 07:58:16 | INFO | fairseq.logging.progress_bar | :     81 / 678 sentences=16\n",
            "2022-12-02 07:58:45 | INFO | fairseq.logging.progress_bar | :     91 / 678 sentences=16\n",
            "2022-12-02 07:59:12 | INFO | fairseq.logging.progress_bar | :    101 / 678 sentences=16\n",
            "2022-12-02 07:59:38 | INFO | fairseq.logging.progress_bar | :    111 / 678 sentences=16\n",
            "2022-12-02 08:00:04 | INFO | fairseq.logging.progress_bar | :    121 / 678 sentences=16\n",
            "2022-12-02 08:00:30 | INFO | fairseq.logging.progress_bar | :    131 / 678 sentences=16\n",
            "2022-12-02 08:00:58 | INFO | fairseq.logging.progress_bar | :    141 / 678 sentences=16\n",
            "2022-12-02 08:01:24 | INFO | fairseq.logging.progress_bar | :    151 / 678 sentences=16\n",
            "2022-12-02 08:01:52 | INFO | fairseq.logging.progress_bar | :    161 / 678 sentences=16\n",
            "2022-12-02 08:02:20 | INFO | fairseq.logging.progress_bar | :    171 / 678 sentences=16\n",
            "2022-12-02 08:02:47 | INFO | fairseq.logging.progress_bar | :    181 / 678 sentences=16\n",
            "2022-12-02 08:03:14 | INFO | fairseq.logging.progress_bar | :    191 / 678 sentences=16\n",
            "2022-12-02 08:03:40 | INFO | fairseq.logging.progress_bar | :    201 / 678 sentences=16\n",
            "2022-12-02 08:04:07 | INFO | fairseq.logging.progress_bar | :    211 / 678 sentences=16\n",
            "2022-12-02 08:04:34 | INFO | fairseq.logging.progress_bar | :    221 / 678 sentences=16\n",
            "2022-12-02 08:04:59 | INFO | fairseq.logging.progress_bar | :    231 / 678 sentences=16\n",
            "2022-12-02 08:05:26 | INFO | fairseq.logging.progress_bar | :    241 / 678 sentences=16\n",
            "2022-12-02 08:05:53 | INFO | fairseq.logging.progress_bar | :    251 / 678 sentences=16\n",
            "2022-12-02 08:06:20 | INFO | fairseq.logging.progress_bar | :    261 / 678 sentences=16\n",
            "2022-12-02 08:06:48 | INFO | fairseq.logging.progress_bar | :    271 / 678 sentences=16\n",
            "2022-12-02 08:07:14 | INFO | fairseq.logging.progress_bar | :    281 / 678 sentences=16\n",
            "2022-12-02 08:07:40 | INFO | fairseq.logging.progress_bar | :    291 / 678 sentences=16\n",
            "2022-12-02 08:08:08 | INFO | fairseq.logging.progress_bar | :    301 / 678 sentences=16\n",
            "2022-12-02 08:08:35 | INFO | fairseq.logging.progress_bar | :    311 / 678 sentences=16\n",
            "2022-12-02 08:09:03 | INFO | fairseq.logging.progress_bar | :    321 / 678 sentences=16\n",
            "2022-12-02 08:09:28 | INFO | fairseq.logging.progress_bar | :    331 / 678 sentences=16\n",
            "2022-12-02 08:09:54 | INFO | fairseq.logging.progress_bar | :    341 / 678 sentences=16\n",
            "2022-12-02 08:10:23 | INFO | fairseq.logging.progress_bar | :    351 / 678 sentences=16\n",
            "2022-12-02 08:10:49 | INFO | fairseq.logging.progress_bar | :    361 / 678 sentences=16\n",
            "2022-12-02 08:11:16 | INFO | fairseq.logging.progress_bar | :    371 / 678 sentences=16\n",
            "2022-12-02 08:11:43 | INFO | fairseq.logging.progress_bar | :    381 / 678 sentences=16\n",
            "2022-12-02 08:12:11 | INFO | fairseq.logging.progress_bar | :    391 / 678 sentences=16\n",
            "2022-12-02 08:12:39 | INFO | fairseq.logging.progress_bar | :    401 / 678 sentences=16\n",
            "2022-12-02 08:13:07 | INFO | fairseq.logging.progress_bar | :    411 / 678 sentences=16\n",
            "2022-12-02 08:13:33 | INFO | fairseq.logging.progress_bar | :    421 / 678 sentences=16\n",
            "2022-12-02 08:14:00 | INFO | fairseq.logging.progress_bar | :    431 / 678 sentences=16\n",
            "2022-12-02 08:14:29 | INFO | fairseq.logging.progress_bar | :    441 / 678 sentences=16\n",
            "2022-12-02 08:14:56 | INFO | fairseq.logging.progress_bar | :    451 / 678 sentences=16\n",
            "2022-12-02 08:15:23 | INFO | fairseq.logging.progress_bar | :    461 / 678 sentences=16\n",
            "2022-12-02 08:15:50 | INFO | fairseq.logging.progress_bar | :    471 / 678 sentences=16\n",
            "2022-12-02 08:16:17 | INFO | fairseq.logging.progress_bar | :    481 / 678 sentences=16\n",
            "2022-12-02 08:16:44 | INFO | fairseq.logging.progress_bar | :    491 / 678 sentences=16\n",
            "2022-12-02 08:17:13 | INFO | fairseq.logging.progress_bar | :    501 / 678 sentences=16\n",
            "2022-12-02 08:17:39 | INFO | fairseq.logging.progress_bar | :    511 / 678 sentences=16\n",
            "2022-12-02 08:18:06 | INFO | fairseq.logging.progress_bar | :    521 / 678 sentences=16\n",
            "2022-12-02 08:18:34 | INFO | fairseq.logging.progress_bar | :    531 / 678 sentences=16\n",
            "2022-12-02 08:19:02 | INFO | fairseq.logging.progress_bar | :    541 / 678 sentences=16\n",
            "2022-12-02 08:19:28 | INFO | fairseq.logging.progress_bar | :    551 / 678 sentences=16\n",
            "2022-12-02 08:19:55 | INFO | fairseq.logging.progress_bar | :    561 / 678 sentences=16\n",
            "2022-12-02 08:20:23 | INFO | fairseq.logging.progress_bar | :    571 / 678 sentences=16\n",
            "2022-12-02 08:20:49 | INFO | fairseq.logging.progress_bar | :    581 / 678 sentences=16\n",
            "2022-12-02 08:21:17 | INFO | fairseq.logging.progress_bar | :    591 / 678 sentences=16\n",
            "2022-12-02 08:21:44 | INFO | fairseq.logging.progress_bar | :    601 / 678 sentences=16\n",
            "2022-12-02 08:22:11 | INFO | fairseq.logging.progress_bar | :    611 / 678 sentences=16\n",
            "2022-12-02 08:22:40 | INFO | fairseq.logging.progress_bar | :    621 / 678 sentences=16\n",
            "2022-12-02 08:23:06 | INFO | fairseq.logging.progress_bar | :    631 / 678 sentences=16\n",
            "2022-12-02 08:23:33 | INFO | fairseq.logging.progress_bar | :    641 / 678 sentences=16\n",
            "2022-12-02 08:24:01 | INFO | fairseq.logging.progress_bar | :    651 / 678 sentences=16\n",
            "2022-12-02 08:24:29 | INFO | fairseq.logging.progress_bar | :    661 / 678 sentences=16\n",
            "2022-12-02 08:24:55 | INFO | fairseq.logging.progress_bar | :    671 / 678 sentences=16\n",
            "2022-12-02 08:25:12 | INFO | ofa.evaluate | score_sum: tensor([9754.], device='cuda:0'), score_cnt: tensor([10834.], device='cuda:0'), score: 0.9003\n",
            "2022-12-02 08:25:12 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0\n",
            "2022-12-02 08:25:12 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
            "/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2022-12-02 08:25:22 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmphi6ng34a\n",
            "2022-12-02 08:25:22 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmphi6ng34a/_remote_module_non_scriptable.py\n",
            "2022-12-02 08:25:22 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-12-02 08:25:25 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://\n",
            "2022-12-02 08:25:25 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "2022-12-02 08:25:25 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "2022-12-02 08:25:25 | INFO | fairseq.distributed.utils | initialized host df5edc4d0afe as rank 0\n",
            "2022-12-02 08:25:26 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../../checkpoints/refcoco_large_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{\"data\":\"../../dataset/refcoco_data/refcoco_testA.tsv\",\"bpe_dir\":\"../../utils/BPE\",\"selected_cols\":\"0,4,2,3\"}', 'results_path': '../../results/refcoco'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'refcoco_testA', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 4, 'min_len': 4, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../dataset/refcoco_data/refcoco_testA.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-02 08:25:26 | INFO | ofa.evaluate | loading model(s) from ../../checkpoints/refcoco_large_best.pt\n",
            "tcmalloc: large alloc 1891909632 bytes == 0xe4f22000 @  0x7fc1dfda9b6b 0x7fc1dfdc9379 0x7fc163ce2d57 0x7fc163cd0bc3 0x7fc18f8b4230 0x7fc1b5b5bbc4 0x7fc1b5801a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e858 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69\n",
            "tcmalloc: large alloc 1891909632 bytes == 0x15636c000 @  0x7fc1dfda9b6b 0x7fc1dfdc9379 0x7fc163ce2d57 0x7fc163cd0bc3 0x7fc18f8b4230 0x7fc1b5b5bbc4 0x7fc1b5801a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e858 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69\n",
            "2022-12-02 08:25:35 | INFO | tasks.ofa_task | source dictionary: 59457 types\n",
            "2022-12-02 08:25:35 | INFO | tasks.ofa_task | target dictionary: 59457 types\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "local datafile ../../dataset/refcoco_data/refcoco_testA.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping\n",
            "local datafile ../../dataset/refcoco_data/refcoco_testA.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping\n",
            "file ../../dataset/refcoco_data/refcoco_testA.tsv slice_id 0 row count 5657 total row count 5657\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/content/OFA/models/sequence_generator.py:695: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "2022-12-02 08:26:20 | INFO | fairseq.logging.progress_bar | :     11 / 354 sentences=16\n",
            "2022-12-02 08:26:47 | INFO | fairseq.logging.progress_bar | :     21 / 354 sentences=16\n",
            "2022-12-02 08:27:13 | INFO | fairseq.logging.progress_bar | :     31 / 354 sentences=16\n",
            "2022-12-02 08:27:41 | INFO | fairseq.logging.progress_bar | :     41 / 354 sentences=16\n",
            "2022-12-02 08:28:09 | INFO | fairseq.logging.progress_bar | :     51 / 354 sentences=16\n",
            "2022-12-02 08:28:38 | INFO | fairseq.logging.progress_bar | :     61 / 354 sentences=16\n",
            "2022-12-02 08:29:05 | INFO | fairseq.logging.progress_bar | :     71 / 354 sentences=16\n",
            "2022-12-02 08:29:31 | INFO | fairseq.logging.progress_bar | :     81 / 354 sentences=16\n",
            "2022-12-02 08:29:59 | INFO | fairseq.logging.progress_bar | :     91 / 354 sentences=16\n",
            "2022-12-02 08:30:27 | INFO | fairseq.logging.progress_bar | :    101 / 354 sentences=16\n",
            "2022-12-02 08:30:54 | INFO | fairseq.logging.progress_bar | :    111 / 354 sentences=16\n",
            "2022-12-02 08:31:21 | INFO | fairseq.logging.progress_bar | :    121 / 354 sentences=16\n",
            "2022-12-02 08:31:50 | INFO | fairseq.logging.progress_bar | :    131 / 354 sentences=16\n",
            "2022-12-02 08:32:16 | INFO | fairseq.logging.progress_bar | :    141 / 354 sentences=16\n",
            "2022-12-02 08:32:44 | INFO | fairseq.logging.progress_bar | :    151 / 354 sentences=16\n",
            "2022-12-02 08:33:12 | INFO | fairseq.logging.progress_bar | :    161 / 354 sentences=16\n",
            "2022-12-02 08:33:41 | INFO | fairseq.logging.progress_bar | :    171 / 354 sentences=16\n",
            "2022-12-02 08:34:08 | INFO | fairseq.logging.progress_bar | :    181 / 354 sentences=16\n",
            "2022-12-02 08:34:37 | INFO | fairseq.logging.progress_bar | :    191 / 354 sentences=16\n",
            "2022-12-02 08:35:04 | INFO | fairseq.logging.progress_bar | :    201 / 354 sentences=16\n",
            "2022-12-02 08:35:31 | INFO | fairseq.logging.progress_bar | :    211 / 354 sentences=16\n",
            "2022-12-02 08:35:57 | INFO | fairseq.logging.progress_bar | :    221 / 354 sentences=16\n",
            "2022-12-02 08:36:25 | INFO | fairseq.logging.progress_bar | :    231 / 354 sentences=16\n",
            "2022-12-02 08:36:51 | INFO | fairseq.logging.progress_bar | :    241 / 354 sentences=16\n",
            "2022-12-02 08:37:18 | INFO | fairseq.logging.progress_bar | :    251 / 354 sentences=16\n",
            "2022-12-02 08:37:46 | INFO | fairseq.logging.progress_bar | :    261 / 354 sentences=16\n",
            "2022-12-02 08:38:12 | INFO | fairseq.logging.progress_bar | :    271 / 354 sentences=16\n",
            "2022-12-02 08:38:40 | INFO | fairseq.logging.progress_bar | :    281 / 354 sentences=16\n",
            "2022-12-02 08:39:07 | INFO | fairseq.logging.progress_bar | :    291 / 354 sentences=16\n",
            "2022-12-02 08:39:34 | INFO | fairseq.logging.progress_bar | :    301 / 354 sentences=16\n",
            "2022-12-02 08:40:03 | INFO | fairseq.logging.progress_bar | :    311 / 354 sentences=16\n",
            "2022-12-02 08:40:31 | INFO | fairseq.logging.progress_bar | :    321 / 354 sentences=16\n",
            "2022-12-02 08:40:57 | INFO | fairseq.logging.progress_bar | :    331 / 354 sentences=16\n",
            "2022-12-02 08:41:26 | INFO | fairseq.logging.progress_bar | :    341 / 354 sentences=16\n",
            "2022-12-02 08:41:53 | INFO | fairseq.logging.progress_bar | :    351 / 354 sentences=16\n",
            "2022-12-02 08:42:00 | INFO | ofa.evaluate | score_sum: tensor([5256.], device='cuda:0'), score_cnt: tensor([5657.], device='cuda:0'), score: 0.9291\n",
            "2022-12-02 08:42:00 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0\n",
            "2022-12-02 08:42:00 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
            "/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2022-12-02 08:42:09 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmpy98c0yre\n",
            "2022-12-02 08:42:09 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmpy98c0yre/_remote_module_non_scriptable.py\n",
            "2022-12-02 08:42:09 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-12-02 08:42:11 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://\n",
            "2022-12-02 08:42:11 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "2022-12-02 08:42:11 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "2022-12-02 08:42:11 | INFO | fairseq.distributed.utils | initialized host df5edc4d0afe as rank 0\n",
            "2022-12-02 08:42:13 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../../checkpoints/refcoco_large_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{\"data\":\"../../dataset/refcoco_data/refcoco_testB.tsv\",\"bpe_dir\":\"../../utils/BPE\",\"selected_cols\":\"0,4,2,3\"}', 'results_path': '../../results/refcoco'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'refcoco_testB', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 4, 'min_len': 4, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../dataset/refcoco_data/refcoco_testB.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-02 08:42:13 | INFO | ofa.evaluate | loading model(s) from ../../checkpoints/refcoco_large_best.pt\n",
            "tcmalloc: large alloc 1891909632 bytes == 0xe6628000 @  0x7f5efc30cb6b 0x7f5efc32c379 0x7f5e80245d57 0x7f5e80233bc3 0x7f5eabe17230 0x7f5ed20bebc4 0x7f5ed1d64a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e858 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69\n",
            "tcmalloc: large alloc 1891909632 bytes == 0x157a9a000 @  0x7f5efc30cb6b 0x7f5efc32c379 0x7f5e80245d57 0x7f5e80233bc3 0x7f5eabe17230 0x7f5ed20bebc4 0x7f5ed1d64a3d 0x5d746e 0x5d813c 0x4ff515 0x49caa1 0x55e858 0x5d7cf1 0x49ec69 0x55e858 0x5d7cf1 0x49caa1 0x5d7c18 0x49ec69 0x5d7c18 0x49ca7c 0x55e858 0x5d7cf1 0x5d77c6 0x561051 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69\n",
            "2022-12-02 08:42:17 | INFO | tasks.ofa_task | source dictionary: 59457 types\n",
            "2022-12-02 08:42:17 | INFO | tasks.ofa_task | target dictionary: 59457 types\n",
            "/usr/local/lib/python3.8/dist-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
            "local datafile ../../dataset/refcoco_data/refcoco_testB.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping\n",
            "local datafile ../../dataset/refcoco_data/refcoco_testB.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping\n",
            "file ../../dataset/refcoco_data/refcoco_testB.tsv slice_id 0 row count 5095 total row count 5095\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py:417: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
            "  warnings.warn(\n",
            "/content/OFA/models/sequence_generator.py:695: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  unfin_idx = bbsz_idx // beam_size\n",
            "2022-12-02 08:43:00 | INFO | fairseq.logging.progress_bar | :     11 / 319 sentences=16\n",
            "2022-12-02 08:43:27 | INFO | fairseq.logging.progress_bar | :     21 / 319 sentences=16\n",
            "2022-12-02 08:43:57 | INFO | fairseq.logging.progress_bar | :     31 / 319 sentences=16\n",
            "2022-12-02 08:44:23 | INFO | fairseq.logging.progress_bar | :     41 / 319 sentences=16\n",
            "2022-12-02 08:44:50 | INFO | fairseq.logging.progress_bar | :     51 / 319 sentences=16\n",
            "2022-12-02 08:45:16 | INFO | fairseq.logging.progress_bar | :     61 / 319 sentences=16\n",
            "2022-12-02 08:45:44 | INFO | fairseq.logging.progress_bar | :     71 / 319 sentences=16\n",
            "2022-12-02 08:46:10 | INFO | fairseq.logging.progress_bar | :     81 / 319 sentences=16\n",
            "2022-12-02 08:46:38 | INFO | fairseq.logging.progress_bar | :     91 / 319 sentences=16\n",
            "2022-12-02 08:47:04 | INFO | fairseq.logging.progress_bar | :    101 / 319 sentences=16\n",
            "2022-12-02 08:47:31 | INFO | fairseq.logging.progress_bar | :    111 / 319 sentences=16\n",
            "2022-12-02 08:47:59 | INFO | fairseq.logging.progress_bar | :    121 / 319 sentences=16\n",
            "2022-12-02 08:48:25 | INFO | fairseq.logging.progress_bar | :    131 / 319 sentences=16\n",
            "2022-12-02 08:48:55 | INFO | fairseq.logging.progress_bar | :    141 / 319 sentences=16\n",
            "2022-12-02 08:49:22 | INFO | fairseq.logging.progress_bar | :    151 / 319 sentences=16\n",
            "2022-12-02 08:49:50 | INFO | fairseq.logging.progress_bar | :    161 / 319 sentences=16\n",
            "2022-12-02 08:50:17 | INFO | fairseq.logging.progress_bar | :    171 / 319 sentences=16\n",
            "2022-12-02 08:50:46 | INFO | fairseq.logging.progress_bar | :    181 / 319 sentences=16\n",
            "2022-12-02 08:51:11 | INFO | fairseq.logging.progress_bar | :    191 / 319 sentences=16\n",
            "2022-12-02 08:51:37 | INFO | fairseq.logging.progress_bar | :    201 / 319 sentences=16\n",
            "2022-12-02 08:52:03 | INFO | fairseq.logging.progress_bar | :    211 / 319 sentences=16\n",
            "2022-12-02 08:52:31 | INFO | fairseq.logging.progress_bar | :    221 / 319 sentences=16\n",
            "2022-12-02 08:52:59 | INFO | fairseq.logging.progress_bar | :    231 / 319 sentences=16\n",
            "2022-12-02 08:53:25 | INFO | fairseq.logging.progress_bar | :    241 / 319 sentences=16\n",
            "2022-12-02 08:53:52 | INFO | fairseq.logging.progress_bar | :    251 / 319 sentences=16\n",
            "2022-12-02 08:54:20 | INFO | fairseq.logging.progress_bar | :    261 / 319 sentences=16\n",
            "2022-12-02 08:54:47 | INFO | fairseq.logging.progress_bar | :    271 / 319 sentences=16\n",
            "2022-12-02 08:55:14 | INFO | fairseq.logging.progress_bar | :    281 / 319 sentences=16\n",
            "2022-12-02 08:55:43 | INFO | fairseq.logging.progress_bar | :    291 / 319 sentences=16\n",
            "2022-12-02 08:56:09 | INFO | fairseq.logging.progress_bar | :    301 / 319 sentences=16\n",
            "2022-12-02 08:56:35 | INFO | fairseq.logging.progress_bar | :    311 / 319 sentences=16\n",
            "2022-12-02 08:56:56 | INFO | ofa.evaluate | score_sum: tensor([4345.], device='cuda:0'), score_cnt: tensor([5095.], device='cuda:0'), score: 0.8528\n",
            "2022-12-02 08:56:56 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0\n",
            "2022-12-02 08:56:56 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
            "/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2022-12-02 08:57:06 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmpwqnewq7b\n",
            "2022-12-02 08:57:06 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmpwqnewq7b/_remote_module_non_scriptable.py\n",
            "2022-12-02 08:57:06 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-12-02 08:57:08 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://\n",
            "2022-12-02 08:57:08 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "2022-12-02 08:57:08 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "2022-12-02 08:57:08 | INFO | fairseq.distributed.utils | initialized host df5edc4d0afe as rank 0\n",
            "2022-12-02 08:57:10 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../../checkpoints/refcocoplus_large_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{\"data\":\"../../dataset/refcocoplus_data/refcocoplus_val.tsv\",\"bpe_dir\":\"../../utils/BPE\",\"selected_cols\":\"0,4,2,3\"}', 'results_path': '../../results/refcocoplus'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'refcocoplus_val', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 4, 'min_len': 4, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../dataset/refcocoplus_data/refcocoplus_val.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-02 08:57:10 | INFO | ofa.evaluate | loading model(s) from ../../checkpoints/refcocoplus_large_best.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"../../evaluate.py\", line 160, in <module>\n",
            "    cli_main()\n",
            "  File \"../../evaluate.py\", line 154, in cli_main\n",
            "    distributed_utils.call_main(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 354, in call_main\n",
            "    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 328, in distributed_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"../../evaluate.py\", line 77, in main\n",
            "    models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task(\n",
            "  File \"/content/OFA/utils/checkpoint_utils.py\", line 434, in load_model_ensemble_and_task\n",
            "    raise IOError(\"Model file not found: {}\".format(filename))\n",
            "OSError: Model file not found: ../../checkpoints/refcocoplus_large_best.pt\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1848) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py\", line 752, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 245, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "../../evaluate.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2022-12-02_08:57:13\n",
            "  host      : df5edc4d0afe\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 1848)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n",
            "/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2022-12-02 08:57:17 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmp2l6e3pan\n",
            "2022-12-02 08:57:17 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmp2l6e3pan/_remote_module_non_scriptable.py\n",
            "2022-12-02 08:57:17 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-12-02 08:57:19 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://\n",
            "2022-12-02 08:57:19 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "2022-12-02 08:57:19 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "2022-12-02 08:57:19 | INFO | fairseq.distributed.utils | initialized host df5edc4d0afe as rank 0\n",
            "2022-12-02 08:57:21 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../../checkpoints/refcocoplus_large_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{\"data\":\"../../dataset/refcocoplus_data/refcocoplus_testA.tsv\",\"bpe_dir\":\"../../utils/BPE\",\"selected_cols\":\"0,4,2,3\"}', 'results_path': '../../results/refcocoplus'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'refcocoplus_testA', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 4, 'min_len': 4, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../dataset/refcocoplus_data/refcocoplus_testA.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-02 08:57:21 | INFO | ofa.evaluate | loading model(s) from ../../checkpoints/refcocoplus_large_best.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"../../evaluate.py\", line 160, in <module>\n",
            "    cli_main()\n",
            "  File \"../../evaluate.py\", line 154, in cli_main\n",
            "    distributed_utils.call_main(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 354, in call_main\n",
            "    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 328, in distributed_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"../../evaluate.py\", line 77, in main\n",
            "    models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task(\n",
            "  File \"/content/OFA/utils/checkpoint_utils.py\", line 434, in load_model_ensemble_and_task\n",
            "    raise IOError(\"Model file not found: {}\".format(filename))\n",
            "OSError: Model file not found: ../../checkpoints/refcocoplus_large_best.pt\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1879) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py\", line 752, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 245, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "../../evaluate.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2022-12-02_08:57:24\n",
            "  host      : df5edc4d0afe\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 1879)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n",
            "/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2022-12-02 08:57:28 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmpxwbzduh_\n",
            "2022-12-02 08:57:28 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmpxwbzduh_/_remote_module_non_scriptable.py\n",
            "2022-12-02 08:57:28 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-12-02 08:57:30 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://\n",
            "2022-12-02 08:57:30 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "2022-12-02 08:57:30 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "2022-12-02 08:57:30 | INFO | fairseq.distributed.utils | initialized host df5edc4d0afe as rank 0\n",
            "2022-12-02 08:57:32 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../../checkpoints/refcocoplus_large_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{\"data\":\"../../dataset/refcocoplus_data/refcocoplus_testB.tsv\",\"bpe_dir\":\"../../utils/BPE\",\"selected_cols\":\"0,4,2,3\"}', 'results_path': '../../results/refcocoplus'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'refcocoplus_testB', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 4, 'min_len': 4, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../dataset/refcocoplus_data/refcocoplus_testB.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-02 08:57:32 | INFO | ofa.evaluate | loading model(s) from ../../checkpoints/refcocoplus_large_best.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"../../evaluate.py\", line 160, in <module>\n",
            "    cli_main()\n",
            "  File \"../../evaluate.py\", line 154, in cli_main\n",
            "    distributed_utils.call_main(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 354, in call_main\n",
            "    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 328, in distributed_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"../../evaluate.py\", line 77, in main\n",
            "    models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task(\n",
            "  File \"/content/OFA/utils/checkpoint_utils.py\", line 434, in load_model_ensemble_and_task\n",
            "    raise IOError(\"Model file not found: {}\".format(filename))\n",
            "OSError: Model file not found: ../../checkpoints/refcocoplus_large_best.pt\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1912) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py\", line 752, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 245, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "../../evaluate.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2022-12-02_08:57:35\n",
            "  host      : df5edc4d0afe\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 1912)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n",
            "/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2022-12-02 08:57:39 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmp_o1a2ip8\n",
            "2022-12-02 08:57:39 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmp_o1a2ip8/_remote_module_non_scriptable.py\n",
            "2022-12-02 08:57:39 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-12-02 08:57:41 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://\n",
            "2022-12-02 08:57:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "2022-12-02 08:57:41 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "2022-12-02 08:57:41 | INFO | fairseq.distributed.utils | initialized host df5edc4d0afe as rank 0\n",
            "2022-12-02 08:57:43 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../../checkpoints/refcocog_large_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{\"data\":\"../../dataset/refcocog_data/refcocog_val.tsv\",\"bpe_dir\":\"../../utils/BPE\",\"selected_cols\":\"0,4,2,3\"}', 'results_path': '../../results/refcocog'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'refcocog_val', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 4, 'min_len': 4, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../dataset/refcocog_data/refcocog_val.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-02 08:57:43 | INFO | ofa.evaluate | loading model(s) from ../../checkpoints/refcocog_large_best.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"../../evaluate.py\", line 160, in <module>\n",
            "    cli_main()\n",
            "  File \"../../evaluate.py\", line 154, in cli_main\n",
            "    distributed_utils.call_main(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 354, in call_main\n",
            "    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 328, in distributed_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"../../evaluate.py\", line 77, in main\n",
            "    models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task(\n",
            "  File \"/content/OFA/utils/checkpoint_utils.py\", line 434, in load_model_ensemble_and_task\n",
            "    raise IOError(\"Model file not found: {}\".format(filename))\n",
            "OSError: Model file not found: ../../checkpoints/refcocog_large_best.pt\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1943) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py\", line 752, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 245, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "../../evaluate.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2022-12-02_08:57:46\n",
            "  host      : df5edc4d0afe\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 1943)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n",
            "/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  warnings.warn(\n",
            "2022-12-02 08:57:50 | INFO | torch.distributed.nn.jit.instantiator | Created a temporary directory at /tmp/tmpkqzj7iks\n",
            "2022-12-02 08:57:50 | INFO | torch.distributed.nn.jit.instantiator | Writing /tmp/tmpkqzj7iks/_remote_module_non_scriptable.py\n",
            "2022-12-02 08:57:50 | INFO | numexpr.utils | NumExpr defaulting to 4 threads.\n",
            "2022-12-02 08:57:52 | INFO | fairseq.distributed.utils | distributed init (rank 0): env://\n",
            "2022-12-02 08:57:52 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "2022-12-02 08:57:52 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "2022-12-02 08:57:52 | INFO | fairseq.distributed.utils | initialized host df5edc4d0afe as rank 0\n",
            "2022-12-02 08:57:54 | INFO | ofa.evaluate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 7, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '../../checkpoints/refcocog_large_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{\"data\":\"../../dataset/refcocog_data/refcocog_test.tsv\",\"bpe_dir\":\"../../utils/BPE\",\"selected_cols\":\"0,4,2,3\"}', 'results_path': '../../results/refcocog'}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 16, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 16, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'refcocog_test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 4, 'min_len': 4, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 3, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'refcoco', 'data': '../../dataset/refcocog_data/refcocog_test.tsv', 'selected_cols': None, 'bpe': None, 'bpe_dir': None, 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 128, 'max_tgt_length': 30, 'code_dict_size': 8192, 'patch_image_size': 480, 'orig_patch_image_size': 256, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_acc': False, 'eval_args': '{}', 'eval_print_samples': False, 'max_image_size': 512, 'scst': False, 'scst_args': '{}'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2022-12-02 08:57:54 | INFO | ofa.evaluate | loading model(s) from ../../checkpoints/refcocog_large_best.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"../../evaluate.py\", line 160, in <module>\n",
            "    cli_main()\n",
            "  File \"../../evaluate.py\", line 154, in cli_main\n",
            "    distributed_utils.call_main(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 354, in call_main\n",
            "    distributed_main(cfg.distributed_training.device_id, main, cfg, kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/fairseq/distributed/utils.py\", line 328, in distributed_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"../../evaluate.py\", line 77, in main\n",
            "    models, saved_cfg, task = checkpoint_utils.load_model_ensemble_and_task(\n",
            "  File \"/content/OFA/utils/checkpoint_utils.py\", line 434, in load_model_ensemble_and_task\n",
            "    raise IOError(\"Model file not found: {}\".format(filename))\n",
            "OSError: Model file not found: ../../checkpoints/refcocog_large_best.pt\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 1974) of binary: /usr/bin/python3\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 193, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 189, in main\n",
            "    launch(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launch.py\", line 174, in launch\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/run.py\", line 752, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/launcher/api.py\", line 245, in launch_agent\n",
            "    raise ChildFailedError(\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "============================================================\n",
            "../../evaluate.py FAILED\n",
            "------------------------------------------------------------\n",
            "Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "------------------------------------------------------------\n",
            "Root Cause (first observed failure):\n",
            "[0]:\n",
            "  time      : 2022-12-02_08:57:57\n",
            "  host      : df5edc4d0afe\n",
            "  rank      : 0 (local_rank: 0)\n",
            "  exitcode  : 1 (pid: 1974)\n",
            "  error_file: <N/A>\n",
            "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MVWsIsXlik22"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}